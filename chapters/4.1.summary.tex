%\section{Summary}\label{sec:orch_summary}

%Software regression testing is actively researched~\cite{rosero_15_2016,bin_ali_search_2019,YooHarman10RegressionTestingSurvey}, and many techniques have been proposed, including test case selection~\cite{kazmi_effective_2017} and prioritization~\cite{khatibsyarbini_test_2018}.

%Both test case selection (\tcs) and test case prioritization (\tcp) techniques aim at detecting regression failures, but they follow different strategies. 
%In \tcs, when a new software version is released, a subset of test cases is selected from the available test suite aiming at exercising all the latest code changes. 
%\tcs is proposed as an alternative to a \textit{retest-all} (i.e., running all tests at each version) strategy that is not sustainable in many practical cases.
%On the other hand, in \tcp the test suite is re-ordered, aiming at executing first those test cases that are more likely to fail. As, of course, we cannot know in advance which test cases discover which failures, different \tcp criteria have been proposed, such as code coverage. 
 
%Many \tcs and \tcp approaches have been proposed~\cite{soetens2016change,legunsen2016,henard2016,luo2018static}.
%Our research goal here is not that of inventing yet another approach, but rather to understand if and how \tcs and \tcp  should be used in combination, i.e.:
%when a new software version is released, is it more convenient to apply a \tcs approach or instead a \tcp one?
%Intuitively, a combination of both techniques would provide the most benefit, but what are the resulting challenges and drawbacks of this approach?
%Notwithstanding the vast literature on  regression testing, 
%such type of questions remain largely unanswered.

We understand \textit{test suite orchestration} as a series of steps that can be performed before the execution of a test suite, with the objective of improving the effectiveness and efficiency of the suite.
This can have an impact in the moments that immediately follow the orchestration, as well as in the long-term evolution, health and usefulness of the suite, as it adapts to an SUT that is also continuously evolving.

As a step towards the goal of fully automated orchestration of test suites that can be useful in real-world software, 
we focus here on regression testing techniques extracted from the existing literature that have been conceived for practical relevance and scalability.
Specifically, as a representative \tcs approach we adopt \ek~\cite{gligoricEk} while for \tcp we use \fs~\cite{miranda_fast}.
The criteria used for selecting these tools were: their cost-effectiveness and simplicity of application; their availability as open-source programs; finally, also for convenience as authors of both tools were also involved with the development of the current study.

Concerning \tcs, in an empirical study conducted in 2014~\cite{gligoric_empirical}, the authors observed that many techniques were not adopted in practice and developers mostly continued to perform manual selection of test cases.  
Motivated by this study, Gligoric et al.~\cite{gligoricEk} proposed  \ek,  a lightweight \tcs technique that leverages file dependencies.
Besides the original paper on \ek, several follow-up studies showed the benefit of file-based selection over other approaches~\cite{legunsen2016, Zhang18HybridRTS}.

Concerning \tcp, in a recent  study Miranda et al.~\cite{miranda_fast} showed that many existing techniques do not scale-up to large test suites.
They hence proposed the \fs approach that applies Locality-Sensitive Hashing (LSH) techniques~\cite{Leskovec:2014} for similarity-based prioritization.
In the original work, the authors assess \fs against several competing \tcp techniques, showing that it gives comparable effectiveness but with higher efficiency.

This work stems from the simple yet powerful idea of comparing these two approaches---\tcs by \ek and \tcp by \fs---and possibly taking the advantages of each while overcoming their potential shortcomings. 
%
We make the following two observations:
\begin{itemize}
\item \ek comes with no notion of test case priority: it assumes that all the selected test cases are run and makes no distinction about whether a failure is found by the first or the last executed test case;
\item \fs reorders tests with the goal to detect failures early, but does not consider recent code changes, whereas we know from practice that these are related with failures, e.g.,~\cite{knauss2015supporting,elbaum2014techniques}.
% quickly allows anticipated
\end{itemize}

By combining \ek and \fs, we  aim at developing 
a \textit{practical} and \textit{effective} approach to regression testing that we call \emph{\fz}.
This is meant to be practical because it combines two scalable techniques, and effective because it overcomes the above shortcomings of each.
In particular, this combined approach aims to decrease \textit{developer feedback time}, which is the time it takes for a developer to receive a test failure notification once testing begins.

%On the one side, \fz could be understood as just a technique that integrates \ek and \fs. 
%On the other side, we see an interesting scientific novelty in this approach. 
%In fact, by combining \textit{file-based} selection with \textit{similarity-based} prioritization it implements a \textit{multi-objective regression technique} in line with the case made by Harman~\cite{harman2011making}.
%Indeed, research in combining multiple criteria in the context of one technique is very active, e.g.,~\cite{epitropakis2015empirical,garousi2018multi}.
%%, as it has been shown that hybrid or multi-criteria are more effective.
%Less attention has been devoted to combining multiple criteria while addressing regression techniques together, which we call \textit{regression test orchestration}.
%For example, Silva et al.~\cite{silva2016hybrid} proposed to combine prioritization and selection based on function criticality (hence manually); 
%Shi et al.~\cite{shi2015comparing} combined and evaluated test reduction (based on coverage) and selection (based on changes). 
%To the best of our knowledge, \textit{\fz is the first regression test orchestration approach that combines file-based selection with similarity-based  prioritization.}

Clearly \fz is one instance within a plethora of possible combinations of many existing \tcs and \tcp approaches, and further studies should be conducted to evaluate  different combinations.
Indeed, following the case made by Harman~\cite{harman2011making},
research in combining multiple criteria in the context of one regression technique is very active, e.g.,~\cite{epitropakis2015empirical,garousi2018multi}.
Much less attention has been devoted so far to using multiple criteria while combining different regression techniques, which we see as an essential part of test suite orchestration.
Di Nardo et al.~\cite{di2015coverage} applied and assessed minimization, selection and prioritization techniques on a single industrial case study, but only considering coverage-based criteria;  Silva et al.~\cite{silva2016hybrid} proposed to combine prioritization and selection based on function criticality (assessed manually); Najafi et al.~\cite{najafi2019improving} evaluated selection and prioritization based on test execution history on a large industrial system;
Shi et al.~\cite{shi2015comparing} combined and evaluated test reduction (based on coverage) and selection (based on changes). 
\fz is the first regression test orchestration approach that combines file-based \tcs with similarity-based \tcp.

We compared \ek, \fs and their orchestration through \fz using a set of 12 projects (from the \dfj repository~\cite{just2014defects4j}).
Our results shows that for most subjects, executing a change-aware selection of test cases (in random ordering) detects the first failure faster than executing the whole prioritized suite (based on similarity). However, we also observed that adding \fs ordering on top of \ek selection further improves effectiveness at negligible additional cost.

To conclude this study and provide a direction for future evolution of test orchestration strategies, we provide a discussion on methods of incorporating other \tcs or \tcp techniques, along with potential combinations with \tsr and \tsa approaches.

\noindent
In summary, our contributions include:
\begin{itemize}
\item an empirical study comparing \tcs against \tcp, and their orchestration against each technique alone;
\item the novel \fz approach to regression testing that combines filed-based \tcs and similarity-based \tcp;
%\item the evaluation of \fz under limited test budgets;
%the effectiveness and time efficiency of two different approaches to combine \tcs and \tcp, also under decreasing test budgets; 
\item a replication package\footnote{Available at: \url{https://doi.org/10.5281/zenodo.5851288}} including \fz implementation and all data from the study.
%In this paper, we mark with~\textdagger~any sentence that refers to additional information found in the replication package.}.
%\footnote{Reference is omitted now to ensure anonymity, and will be made available with the CR.}.
\end{itemize}

For practitioners our results signify not only a further confirmation of change-aware selection validity, but also the convenience of executing the selected test cases in prioritized order based on their similarity.
In fact, using state-of-art scalable techniques as \fs over the selected test subset can help detect failures faster at virtually no cost.
For researchers, this paper signifies the importance of studying regression techniques as an orchestration rather than individually, and 
opens up the floor for many potential experiments in which various \tcs techniques are compared against, or combined with, various \tcp techniques. 

In~\Cref{sec:orch_background} we provide a short summary of the \tcs and \tcp approaches that we compare and combine, while in~\Cref{sec:orch_fastazi} we present \fz. 
The study methodology is described in~\Cref{sec:orch_experiments} and the results are discussed in~\Cref{sec:orch_results}.
%In Section~\ref{sec:orch_} we overview related work, 
Finally, in~\Cref{sec:orch_discussion} we draw brief conclusions derived from this study and discuss the possible next steps in the evolution of this work. 
