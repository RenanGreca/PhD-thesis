%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Renan Greca at 2022-12-01 10:45:43 +0100 


%% Saved with string encoding Unicode (UTF-8) 

@inproceedings{rossi2020defensive_p,
  title={Defensive Programming for Smart Home Cybersecurity},
  author={Rossi, Maria Teresa and Greca, Renan and Iovino, Ludovico and Giacinto, Giorgio and Bertolino, Antonia},
  booktitle={2020 IEEE European Symposium on Security and Privacy Workshops (EuroS\&PW)},
  pages={600--605},
  year={2020},
  organization={IEEE},
  doi={10.1109/EuroSPW51379.2020.00087}
}

@inproceedings{greca_comparing_2022_p,
	abstract = {Test case selection (TCS) and test case prioritization (TCP) techniques can reduce time to detect the first test failure. Although these techniques have been extensively studied in combination and isolation, they have not been compared one against the other. In this paper, we perform an empirical study directly comparing TCS and TCP approaches, represented by the tools Ekstazi and FAST, respectively. Furthermore, we develop the first combination, named Fastazi, of file-based TCS and similarity-based TCP and evaluate its benefit and cost against each individual technique. We performed our experiments using 12 Java-based open-source projects. Our results show that, in the median case, the combined approach detects the first failure nearly two times faster than either Ekstazi alone (with random test ordering) or FAST alone (without TCS). Statistical analysis shows that the effectiveness of Fastazi is higher than that of Ekstazi, which in turn is higher than that of FAST. On the other hand, FAST adds the least overhead to testing time, while the difference between the additional time needed by Ekstazi and Fastazi is negligible. Fastazi can also improve failure detection in scenarios where the time available for testing is restricted.},
	address = {Pittsburgh, USA},
	author = {Greca, Renan and Miranda, Breno and Gligoric, Milos and Bertolino, Antonia},
	booktitle = {Proceedings of the 3rd {ACM}/{IEEE} {International} {Conference} on {Automation} of {Software} {Test}},
	date-modified = {2022-12-01 10:41:53 +0100},
	doi = {10.1145/3524481.3527223},
	month = may,
	publisher = {ACM/IEEE},
	title = {Comparing and combining file-based selection and similarity-based prioritization towards regression test orchestration},
	year = {2022}}

@article{greca_live_2022_p,
author = {Greca, Renan and Miranda, Breno and Bertolino, Antonia},
title = {State of Practical Applicability of Regression Testing Research: A Live Systematic Literature Review},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3579851},
abstract = {Context: Software regression testing refers to rerunning test cases after the system under test is modified, ascertaining that the changes have not (re-)introduced failures. Not all researchers’ approaches consider applicability and scalability concerns, and not many have produced an impact in practice. Objective: One goal is to investigate industrial relevance and applicability of proposed approaches. Another is providing a live review, open to continuous updates by the community. Method: A systematic review of regression testing studies that are clearly motivated by or validated against industrial relevance and applicability is conducted. It is complemented by follow-up surveys with authors of the selected papers and 23 practitioners. Results: A set of 79 primary studies published between 2016-2022 is collected and classified according to approaches and metrics. Aspects relative to their relevance and impact are discussed, also based on their authors’ feedback. All the data are made available from the live repository that accompanies the study. Conclusions: While widely motivated by industrial relevance and applicability, not many approaches are evaluated in industrial or large-scale open-source systems, and even fewer approaches have been adopted in practice. Some challenges hindering the implementation of relevant approaches are synthesized, also based on the practitioners’ feedback.},
journal = {ACM Computing Surveys},
month = {jan}
}

@inproceedings{greca_orchestration_2023_p,
	address = {Melbourne, Australia},
	author = {Greca, Renan and Miranda, Breno and Bertolino, Antonia},
	booktitle = {Proceedings of the 4th {ACM}/{IEEE} {International} {Conference} on {Automation} of {Software} {Test}},
	date-modified = {2023-03-13 10:41:53 +0100},
	month = may,
	publisher = {ACM/IEEE},
	title = {Orchestration Strategies for Regression Test Suites},
	year = {2023}}
